# “公益AI之星”挑战赛-新冠疫情相似句对判定大赛
天池大赛疫情文本挑战赛线上第四名代码开源[（比赛链接）](https://tianchi.aliyun.com/competition/entrance/231776/information)

## 赛题简介
本次大赛主要面对疫情抗击，疫情知识问答应用得到普遍推广。是由
达摩院联合医疗服务机构妙健康发布的疫情相似句对判定任务，比赛整理
近万条真实语境下疫情相关的肺炎、支原体肺炎、支气管炎、
上呼吸道感染、肺结核、哮喘、胸膜炎、肺气肿、感冒、咳血等患者提问句对。
而任务就是判定两问句是否相似，属于问句相似性判断任务。
以下是示例句子：

| query1 | query2 | label |
| :------: | :------: | :------: |
| 剧烈运动后咯血,是怎么了?| 剧烈运动后咯血是什么原因？| 1 |
| 剧烈运动后咯血,是怎么了?| 剧烈运动后为什么会咯血？| 1 |
| 剧烈运动后咯血,是怎么了?| 剧烈运动后咯血，应该怎么处理？| 0 |
| 剧烈运动后咯血,是怎么了?| 剧烈运动后咯血，需要就医吗？| 0 |
| 剧烈运动后咯血,是怎么了?| 剧烈运动后咯血，是否很严重？| 0 |

## 方案简介

###最终方案

本方案预训练采用[roberta_wwm_ext_large](https://github.com/ymcui/Chinese-BERT-wwm)

首先将query1,query2作为句对传入到robert中。

用bert输出的最后一层求平均并与[CLS]拼接

由于对抗训练可以有效提高模型的鲁棒性和泛化能力。本方案采用Projected Gradient Descent[详见](https://zhuanlan.zhihu.com/p/91269728)。
将扰动附加在bert的word embedding。

为了最大利用数据，本方案采用7折交叉验证。并更换随机种子后又跑了4折。

采用投票方式，并将所有概率求平均后再次投票。公式如下：

vote = ∑argmax(p) + argmax(∑p) * len / 2

由于比赛里写了不鼓励通过多模提高比赛成绩，故没有进行多模融合

剩下的就是玄学调参

线上成绩

| 模型 | 成绩 |
| :------: | :------: |
| roberta| 0.9582 |
| roberta+fgm| 0.9610 |
| roberta+pgd| 0.9630 |

### 没啥用的trick

1.利用传递性进行数据增强，包括保持数据比例，成绩下降（有大佬用了成绩上升，都是玄学）。

2.取出bert后的多层隐藏层做各种操作，成绩下降。

3.bert后接各种层，成绩下降。

4.换用其他预训练模型（包括其他roberta、xlnet），成绩下降。

## 代码说明
project

	|--README.md
	|--data
	    |-- Dataset # 训练数据 
	|--user_data
		|-- model_data # 存放训练模型
			|-- model.dat
		|-- pre-trained #存放预训练模型
	|--prediction_result #存放提交结果
	|--code
	    |-- train.py #训练代码
	    |-- test.py #测试代码
		|-- main.sh #一键运行





